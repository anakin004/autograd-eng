# AutoGrad-Eng

## Educational Project
AutoGrad-Eng is an educational project based on Andrej Karpathy's lecture on the fundamentals of neural networks from the ground up. It includes:

- **Value Nodes** for weights, biases, results, etc.
- **Visualization of backpropagation** and neural network nodes and operations that result in a specific node.
- **Stochastic Gradient Descent (SGD)** for all nodes.
- **Gradient descent optimization**, which updates weights and biases based on the node's current gradient.
- After multiple passes, the neural network's results approach the intended data.

## Additional Learning Resources
Here are some awesome practices related to topics covered in this project:

- [Google Colab Notebook](https://colab.research.google.com/drive/1FPTx1RXtBfc4MaTkf7viZZD4U2F9gtKN?usp=sharing)
- Also, check out Andrej Karpathy's course: [Zero to Hero](https://karpathy.ai/zero-to-hero.html)

#### Example Visualization
Below is an image illustrating the calculation of the loss function and setting gradients using backpropagation:

![image](https://github.com/user-attachments/assets/576a1ebc-f0c4-4dd9-a772-e79a1b5ceac2)
