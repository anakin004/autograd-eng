

== educational project

Based on Andrej Karpathy lecture on the basis of neural networks from the ground up
-- includes Value Nodes for weights, biases, reslults etc
-- visualization of backprop and neural network nodes and operations that results in a specific node
-- includes stochastic gradient descent for all nodes
-- uses gradient descent to change weights and biases based on the nodes current gradient
-- after passes the neural nets results approach intended data


+---+
this demo might not seem like a conventional neural network but it represent the neural network in how all the weights and biases
and mathmatical operations like add, sub, divide, mult, tanh, pow, etc, result in a specific node 

-- this demo and other visualizations in the jupyter notebook file use graphviz which I highly recommend checking out in the project reqs

![image](https://github.com/user-attachments/assets/576a1ebc-f0c4-4dd9-a772-e79a1b5ceac2)
